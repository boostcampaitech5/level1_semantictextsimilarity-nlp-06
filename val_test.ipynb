{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import yaml\n",
    "from models.model import Model\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 확인하고 싶은 모델의 result 폴더 경로로 바꿔주세요.\n",
    "result_path = '/opt/ml/level1_semantictextsimilarity-nlp-06/results/2023-04-19-15:31:39_SE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at snunlp/KR-ELECTRA-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at snunlp/KR-ELECTRA-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 그냥 실행하고 넘어가세요.\n",
    "def find_files(folder_path):\n",
    "    ckpt_path = \"\"\n",
    "    yaml_path = \"\"\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\"last.ckpt\"):\n",
    "                ckpt_path = os.path.abspath(os.path.join(root, file))\n",
    "            elif file.endswith(\".yaml\"):\n",
    "                yaml_path = os.path.abspath(os.path.join(root, file))\n",
    "            if ckpt_path and yaml_path:\n",
    "                break\n",
    "        if ckpt_path and yaml_path:\n",
    "            break\n",
    "    return ckpt_path, yaml_path\n",
    "\n",
    "def tokenizing(df):\n",
    "    data = []\n",
    "\n",
    "    for idx, item in df.iterrows():\n",
    "        # 두 입력 문장을 [SEP] 토큰으로 이어붙여서 전처리\n",
    "        text = '[SEP]'.join([item[text_column] for text_column in text_columns])\n",
    "        outputs = tokenizer(text, add_special_tokens=True, padding='max_length', truncation=True)\n",
    "        data.append(outputs['input_ids'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_df, val_df, predict_df = utils.get_data()\n",
    "ckpt_path, yaml_path = find_files(result_path)\n",
    "\n",
    "model = Model.load_from_checkpoint(ckpt_path)\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "with open('baselines/baseline_config.yaml') as f:\n",
    "    CFG = yaml.load(f, Loader=yaml.FullLoader)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(CFG['train']['model_name'], model_max_length=CFG['train']['max_len'])\n",
    "text_columns = ['sentence_1', 'sentence_2']\n",
    "\n",
    "\n",
    "val_df = val_df[['sentence_1', 'sentence_2', 'label']]\n",
    "\n",
    "result_list = []\n",
    "for i in range(10):\n",
    "    sample_df = val_df[i*55:(i+1)*55].reset_index()\n",
    "    result = model(torch.tensor(tokenizing(sample_df)).to('cuda'))\n",
    "    result = result.detach().cpu().squeeze().tolist()\n",
    "    result_list.extend(result)\n",
    "result_df = pd.DataFrame({'predict': result_list})\n",
    "predict_df = pd.concat([val_df, result_df], axis=1)\n",
    "\n",
    "sorted_df = pd.concat([predict_df, abs(predict_df['label'] - predict_df['predict'])], axis=1).sort_values([0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>자브라 대만족이죠!</td>\n",
       "      <td>Jabra에 매우 만족합니다!</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.225088</td>\n",
       "      <td>2.974912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>(선언만 해두고 차후에 적정시점 실행)</td>\n",
       "      <td>(나중에 적절한 시점에 선언하고 실행하면 됨)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.861060</td>\n",
       "      <td>2.661060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>엥 제가 2등인가요? ㅋㅋ</td>\n",
       "      <td>엥 은메달인가요 제가? ㅋㅋ</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>2.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>과장과 공포에 굴복하여 도리어 국민생명을 위협하고 있는 비이성적인 '독일 따라하기'...</td>\n",
       "      <td>과장과 공포에 굴복하여 국민의 생명을 위협하는 불합리한 '독일을 모방'하는 비핵화 ...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.241430</td>\n",
       "      <td>1.841430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>편보다 편이 더 재밌는 영화... 편부터는 보지마</td>\n",
       "      <td>본편보다 영화가 더 재밌어... 본편은 보지마</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.392653</td>\n",
       "      <td>1.792653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ㅋㅋ 실습까지 ㅋㅋ</td>\n",
       "      <td>ㅎㅎ 연습까지</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.559879</td>\n",
       "      <td>1.759879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>국회의원 월급 삭감</td>\n",
       "      <td>국회의원 급여 미지급</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.472321</td>\n",
       "      <td>1.672321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>국가고시 가산점 폐지</td>\n",
       "      <td>518 공무원 가산제 폐지</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.736729</td>\n",
       "      <td>1.663271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>아무래도 상관 없어요.</td>\n",
       "      <td>그것은 정말 중요하지 않습니다.</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.143650</td>\n",
       "      <td>1.656350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>갈수록 뛰는 시간이 늘 것 같은 설렘!!</td>\n",
       "      <td>러닝타임이 길어질수록 더해지는 것 같은 설렘!!</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.831324</td>\n",
       "      <td>1.631324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>남들과다르다는이유만으로 억울한 죽음을 당한 브랜든 티나의 명복을 빕니다</td>\n",
       "      <td>다른 사람들과 다르다는 이유로 부당한 죽음을 당하신 나머지 Brandon Tina를...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.048848</td>\n",
       "      <td>1.551152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>국민연금 자율가입제</td>\n",
       "      <td>국민연금 선택 납부제</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.500658</td>\n",
       "      <td>1.500658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>진짜 고기 짱맛이었습니다 ㅋㅋㅋ</td>\n",
       "      <td>역시나 짱짱이었습니다</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.115572</td>\n",
       "      <td>1.484428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>유은혜교육부총리 적극 지지합니다</td>\n",
       "      <td>비리유치원의 장상화, 유은혜 장관을 지지합니다.</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.350967</td>\n",
       "      <td>1.449033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>분을 두시간으로 늘리고싶다면 이 영화를 추천.</td>\n",
       "      <td>인생에서 두시간을 쓰레기통에 버리고싶다면 보세요.</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.370051</td>\n",
       "      <td>1.429949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>국회의원 세비 및 봉급을 동결합시다</td>\n",
       "      <td>국회의원 월급이나 연봉 삭감을 청원합니다</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.222713</td>\n",
       "      <td>1.422713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>ㅋㅋ너무 재밌었어요!!!</td>\n",
       "      <td>다시 봐도 너무 웃겨요ㅋㅋ</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.784737</td>\n",
       "      <td>1.384737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>피의자 김성수 강력한 처벌 원합니다</td>\n",
       "      <td>강서구 pc방 살인사건 피의자 김성수 감형 반대</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.435249</td>\n",
       "      <td>1.364751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>몇마디 안되는 그의 대사가 가슴을 후벼판다.</td>\n",
       "      <td>그의 몇 줄의 대화가 마음을 아프게 합니다.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.438853</td>\n",
       "      <td>1.361147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>조금이라도 본 게 아까워서라도 웬만하면 끝까지 볼랬는데, 토나올 것 같아 도저히 못...</td>\n",
       "      <td>보다가 중간에 끄고 싶었은데 본게 아까워서 못껐다</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.325340</td>\n",
       "      <td>1.325340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence_1  \\\n",
       "447                                         자브라 대만족이죠!   \n",
       "171                              (선언만 해두고 차후에 적정시점 실행)   \n",
       "29                                      엥 제가 2등인가요? ㅋㅋ   \n",
       "288  과장과 공포에 굴복하여 도리어 국민생명을 위협하고 있는 비이성적인 '독일 따라하기'...   \n",
       "390                        편보다 편이 더 재밌는 영화... 편부터는 보지마   \n",
       "65                                          ㅋㅋ 실습까지 ㅋㅋ   \n",
       "130                                         국회의원 월급 삭감   \n",
       "88                                         국가고시 가산점 폐지   \n",
       "420                                       아무래도 상관 없어요.   \n",
       "454                             갈수록 뛰는 시간이 늘 것 같은 설렘!!   \n",
       "154            남들과다르다는이유만으로 억울한 죽음을 당한 브랜든 티나의 명복을 빕니다   \n",
       "334                                         국민연금 자율가입제   \n",
       "17                                   진짜 고기 짱맛이었습니다 ㅋㅋㅋ   \n",
       "151                                  유은혜교육부총리 적극 지지합니다   \n",
       "141                          분을 두시간으로 늘리고싶다면 이 영화를 추천.   \n",
       "460                                국회의원 세비 및 봉급을 동결합시다   \n",
       "528                                      ㅋㅋ너무 재밌었어요!!!   \n",
       "342                                피의자 김성수 강력한 처벌 원합니다   \n",
       "385                           몇마디 안되는 그의 대사가 가슴을 후벼판다.   \n",
       "290  조금이라도 본 게 아까워서라도 웬만하면 끝까지 볼랬는데, 토나올 것 같아 도저히 못...   \n",
       "\n",
       "                                            sentence_2  label   predict  \\\n",
       "447                                   Jabra에 매우 만족합니다!    4.2  1.225088   \n",
       "171                          (나중에 적절한 시점에 선언하고 실행하면 됨)    1.2  3.861060   \n",
       "29                                     엥 은메달인가요 제가? ㅋㅋ    2.6  0.522100   \n",
       "288  과장과 공포에 굴복하여 국민의 생명을 위협하는 불합리한 '독일을 모방'하는 비핵화 ...    2.4  4.241430   \n",
       "390                          본편보다 영화가 더 재밌어... 본편은 보지마    1.6  3.392653   \n",
       "65                                             ㅎㅎ 연습까지    1.8  3.559879   \n",
       "130                                        국회의원 급여 미지급    1.8  3.472321   \n",
       "88                                      518 공무원 가산제 폐지    2.4  0.736729   \n",
       "420                                  그것은 정말 중요하지 않습니다.    1.8  0.143650   \n",
       "454                         러닝타임이 길어질수록 더해지는 것 같은 설렘!!    2.2  3.831324   \n",
       "154  다른 사람들과 다르다는 이유로 부당한 죽음을 당하신 나머지 Brandon Tina를...    4.6  3.048848   \n",
       "334                                        국민연금 선택 납부제    2.0  3.500658   \n",
       "17                                         역시나 짱짱이었습니다    2.6  1.115572   \n",
       "151                         비리유치원의 장상화, 유은혜 장관을 지지합니다.    2.8  1.350967   \n",
       "141                        인생에서 두시간을 쓰레기통에 버리고싶다면 보세요.    2.8  1.370051   \n",
       "460                             국회의원 월급이나 연봉 삭감을 청원합니다    1.8  3.222713   \n",
       "528                                     다시 봐도 너무 웃겨요ㅋㅋ    1.4  2.784737   \n",
       "342                         강서구 pc방 살인사건 피의자 김성수 감형 반대    2.8  1.435249   \n",
       "385                           그의 몇 줄의 대화가 마음을 아프게 합니다.    3.8  2.438853   \n",
       "290                        보다가 중간에 끄고 싶었은데 본게 아까워서 못껐다    1.0  2.325340   \n",
       "\n",
       "            0  \n",
       "447  2.974912  \n",
       "171  2.661060  \n",
       "29   2.077900  \n",
       "288  1.841430  \n",
       "390  1.792653  \n",
       "65   1.759879  \n",
       "130  1.672321  \n",
       "88   1.663271  \n",
       "420  1.656350  \n",
       "454  1.631324  \n",
       "154  1.551152  \n",
       "334  1.500658  \n",
       "17   1.484428  \n",
       "151  1.449033  \n",
       "141  1.429949  \n",
       "460  1.422713  \n",
       "528  1.384737  \n",
       "342  1.364751  \n",
       "385  1.361147  \n",
       "290  1.325340  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_df.to_csv('val_inference.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
